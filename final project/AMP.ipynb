{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yo-HofRyUvPQ",
        "outputId": "2b073351-51f4-4767-9b42-60602ea7dfa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9WRfjhdU-DY",
        "outputId": "504a7777-4745-4e81-a0e6-f2cc06313e27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/Intro_to_image_processing/Final_Project')\n",
        "!pwd\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7M6L0H8uVC9Q",
        "outputId": "59605453-3e20-40c9-fc7f-d313e9bb6ff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Intro_to_image_processing/Final_Project\n",
            "AMP.ipynb  DAT\tDAT.ipynb  dat_model.py  DAT_x4.pth  DRCT.ipynb  HAT  images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision\n",
        "!pip install addict lmdb tb-nightly\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M94PSdM7VGMY",
        "outputId": "eea4353f-90d3-4439-cac2-6903a14a5d4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n",
            "Collecting addict\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Collecting lmdb\n",
            "  Downloading lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tb-nightly\n",
            "  Downloading tb_nightly-2.17.0a20240530-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tb-nightly) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tb-nightly) (1.64.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tb-nightly) (3.6)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly) (1.25.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tb-nightly) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tb-nightly) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tb-nightly) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tb-nightly) (2.1.5)\n",
            "Installing collected packages: lmdb, addict, tb-nightly\n",
            "Successfully installed addict-2.4.0 lmdb-1.4.1 tb-nightly-2.17.0a20240530\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the DAT repository\n",
        "!git clone https://github.com/XPixelGroup/HAT.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTEnjX-VVLOY",
        "outputId": "69a94fd1-3125-430b-d0a3-0af6afd8105c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'HAT' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change directory to the cloned repo\n",
        "%cd HAT\n",
        "\n",
        "# View the contents of requirements.txt\n",
        "!cat requirements.txt\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTEkISJtVj-O",
        "outputId": "6fdc0cb9-6185-42f1-8652-e6acdff5d354"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Intro_to_image_processing/Final_Project/HAT\n",
            "einops\n",
            "torch>=1.7\n",
            "basicsr==1.3.4.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt --no-deps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxdgo4z6VnTB",
        "outputId": "71647ca0-4a36-4bf0-9dce-689823255a4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting einops (from -r requirements.txt (line 1))\n",
            "  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m836.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (2.3.0+cu121)\n",
            "Collecting basicsr==1.3.4.9 (from -r requirements.txt (line 3))\n",
            "  Downloading basicsr-1.3.4.9.tar.gz (161 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.2/161.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: basicsr\n",
            "  Building wheel for basicsr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for basicsr: filename=basicsr-1.3.4.9-py3-none-any.whl size=194421 sha256=74201c1efb06f258c15f7869c828093f705bf4075fcc46606de6565c6f75729d\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/19/97/8206d928857f2ef0625cb621b689005610515b4841be4e5ddb\n",
            "Successfully built basicsr\n",
            "Installing collected packages: basicsr, einops\n",
            "Successfully installed basicsr-1.3.4.9 einops-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptRCzx5lVqRt",
        "outputId": "aee4ec2a-443c-4670-db06-d25f17176551"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Intro_to_image_processing/Final_Project/HAT\n",
            "cog.yaml  experiments  hat\t  LICENSE  predict.py  requirements.txt  setup.cfg  VERSION\n",
            "datasets  figures      input_dir  options  README.md   results\t\t setup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def adaptive_weighted_mean_filter(image, kernel_size=9, max_intensity_diff=20):\n",
        "    \"\"\"\n",
        "    Apply Adaptive Weighted Mean Filter to the input image.\n",
        "\n",
        "    Parameters:\n",
        "        image (numpy.ndarray): Input image (color or grayscale).\n",
        "        kernel_size (int): Size of the kernel (odd integer).\n",
        "        max_intensity_diff (int): Maximum intensity difference to consider when calculating weights.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Filtered image.\n",
        "    \"\"\"\n",
        "    filtered_image = np.zeros_like(image)\n",
        "\n",
        "    pad = kernel_size // 2\n",
        "    padded_image = cv2.copyMakeBorder(image, pad, pad, pad, pad, cv2.BORDER_REFLECT)\n",
        "\n",
        "    for i in range(pad, padded_image.shape[0] - pad):\n",
        "        for j in range(pad, padded_image.shape[1] - pad):\n",
        "            neighborhood = padded_image[i-pad:i+pad+1, j-pad:j+pad+1]\n",
        "            center_pixel = padded_image[i, j]\n",
        "            weights = np.exp(-np.abs(neighborhood - center_pixel) / max_intensity_diff)\n",
        "            normalized_weights = weights / np.sum(weights, axis=(0, 1))  # Normalize weights for each channel\n",
        "            filtered_value = np.sum(normalized_weights * neighborhood, axis=(0, 1))\n",
        "            filtered_image[i-pad, j-pad] = np.clip(filtered_value, 0, 255)\n",
        "\n",
        "    return filtered_image.astype(np.uint8)\n"
      ],
      "metadata": {
        "id": "nYsqGQwewIDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def max_filter(image, kernel_size):\n",
        "    return cv2.dilate(image, np.ones((kernel_size, kernel_size), np.uint8))\n",
        "\n",
        "def min_filter(image, kernel_size):\n",
        "    return cv2.erode(image, np.ones((kernel_size, kernel_size), np.uint8))\n",
        "\n",
        "def average_filter(image, kernel_size):\n",
        "    return cv2.blur(image, (kernel_size, kernel_size))\n",
        "\n",
        "def median_filter(image, kernel_size):\n",
        "    return cv2.medianBlur(image, kernel_size)\n",
        "\n",
        "def adaptive_bilateral_filter(image, d, sigma_color, sigma_space):\n",
        "    return cv2.bilateralFilter(image, d, sigma_color, sigma_space)\n",
        "\n",
        "def process_images_in_folder(input_folder, output_folder, kernel_size):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    compare_folder=\"compare\"\n",
        "    if not os.path.exists(compare_folder):\n",
        "        os.makedirs(compare_folder)\n",
        "\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith(\".jpg\") or filename.endswith(\".png\") or filename.endswith(\".jpeg\"):\n",
        "            input_path = os.path.join(input_folder, filename)\n",
        "            output_path = os.path.join(output_folder, filename)\n",
        "            compare_path = os.path.join(compare_folder, filename)\n",
        "\n",
        "            original_image = cv2.imread(input_path)\n",
        "            if original_image is None:\n",
        "                print(f\"Could not read image: {input_path}\")\n",
        "                continue\n",
        "\n",
        "\n",
        "            d = 9 # Diameter of each pixel neighborhood\n",
        "            sigma_color = 20  # Filter sigma in the color space\n",
        "            sigma_space = 200  # Filter sigma in the coordinate space\n",
        "            filtered_image = adaptive_bilateral_filter(original_image, d, sigma_color, sigma_space)\n",
        "\n",
        "            cv2.imwrite(output_path, filtered_image)\n",
        "            comparison = np.concatenate((original_image, filtered_image), axis=1)\n",
        "            cv2.imwrite(compare_path, comparison)\n",
        "            print(f\"Processed: {input_path} -> {output_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_folder = \"results/HAT_GAN_Real_SRx4_archived_20240531_024714/visualization/custom\"  # Specify the folder containing your input images\n",
        "    output_folder = \"filtered_image\"  # Specify the folder where you want to save the filtered images\n",
        "    kernel_size = 3  # Adjust kernel size as needed\n",
        "\n",
        "    process_images_in_folder(input_folder, output_folder, kernel_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nM_ke6kb9Pi",
        "outputId": "254b498f-8c64-45ca-d925-999bc999d80f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed: results/HAT_GAN_Real_SRx4_archived_20240531_024714/visualization/custom/1_HAT_GAN_Real_SRx4.png -> filtered_image/1_HAT_GAN_Real_SRx4.png\n",
            "Processed: results/HAT_GAN_Real_SRx4_archived_20240531_024714/visualization/custom/10_HAT_GAN_Real_SRx4.png -> filtered_image/10_HAT_GAN_Real_SRx4.png\n",
            "Processed: results/HAT_GAN_Real_SRx4_archived_20240531_024714/visualization/custom/11_HAT_GAN_Real_SRx4.png -> filtered_image/11_HAT_GAN_Real_SRx4.png\n",
            "Processed: results/HAT_GAN_Real_SRx4_archived_20240531_024714/visualization/custom/12_HAT_GAN_Real_SRx4.png -> filtered_image/12_HAT_GAN_Real_SRx4.png\n",
            "Processed: results/HAT_GAN_Real_SRx4_archived_20240531_024714/visualization/custom/13_HAT_GAN_Real_SRx4.png -> filtered_image/13_HAT_GAN_Real_SRx4.png\n",
            "Processed: results/HAT_GAN_Real_SRx4_archived_20240531_024714/visualization/custom/14_HAT_GAN_Real_SRx4.png -> filtered_image/14_HAT_GAN_Real_SRx4.png\n",
            "Processed: results/HAT_GAN_Real_SRx4_archived_20240531_024714/visualization/custom/15_HAT_GAN_Real_SRx4.png -> filtered_image/15_HAT_GAN_Real_SRx4.png\n",
            "Processed: results/HAT_GAN_Real_SRx4_archived_20240531_024714/visualization/custom/2_HAT_GAN_Real_SRx4.png -> filtered_image/2_HAT_GAN_Real_SRx4.png\n",
            "Processed: results/HAT_GAN_Real_SRx4_archived_20240531_024714/visualization/custom/3_HAT_GAN_Real_SRx4.png -> filtered_image/3_HAT_GAN_Real_SRx4.png\n",
            "Processed: results/HAT_GAN_Real_SRx4_archived_20240531_024714/visualization/custom/4_HAT_GAN_Real_SRx4.png -> filtered_image/4_HAT_GAN_Real_SRx4.png\n",
            "Processed: results/HAT_GAN_Real_SRx4_archived_20240531_024714/visualization/custom/5_HAT_GAN_Real_SRx4.png -> filtered_image/5_HAT_GAN_Real_SRx4.png\n",
            "Processed: results/HAT_GAN_Real_SRx4_archived_20240531_024714/visualization/custom/6_HAT_GAN_Real_SRx4.png -> filtered_image/6_HAT_GAN_Real_SRx4.png\n",
            "Processed: results/HAT_GAN_Real_SRx4_archived_20240531_024714/visualization/custom/7_HAT_GAN_Real_SRx4.png -> filtered_image/7_HAT_GAN_Real_SRx4.png\n",
            "Processed: results/HAT_GAN_Real_SRx4_archived_20240531_024714/visualization/custom/8_HAT_GAN_Real_SRx4.png -> filtered_image/8_HAT_GAN_Real_SRx4.png\n",
            "Processed: results/HAT_GAN_Real_SRx4_archived_20240531_024714/visualization/custom/9_HAT_GAN_Real_SRx4.png -> filtered_image/9_HAT_GAN_Real_SRx4.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python hat/test.py -opt options/test/HAT_GAN_Real_SRx4.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_-CqI5hVu0t",
        "outputId": "0fd63cfc-df8a-4316-b7e9-7da8e036cceb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Disable distributed.\n",
            "Path already exists. Rename it to /content/drive/MyDrive/Colab Notebooks/Intro_to_image_processing/Final_Project/HAT/results/HAT_GAN_Real_SRx4_archived_20240531_040340\n",
            "2024-05-31 04:03:40,718 INFO: \n",
            "                ____                _       _____  ____\n",
            "               / __ ) ____ _ _____ (_)_____/ ___/ / __ \\\n",
            "              / __  |/ __ `// ___// // ___/\\__ \\ / /_/ /\n",
            "             / /_/ // /_/ /(__  )/ // /__ ___/ // _, _/\n",
            "            /_____/ \\__,_//____//_/ \\___//____//_/ |_|\n",
            "     ______                   __   __                 __      __\n",
            "    / ____/____   ____   ____/ /  / /   __  __ _____ / /__   / /\n",
            "   / / __ / __ \\ / __ \\ / __  /  / /   / / / // ___// //_/  / /\n",
            "  / /_/ // /_/ // /_/ // /_/ /  / /___/ /_/ // /__ / /<    /_/\n",
            "  \\____/ \\____/ \\____/ \\____/  /_____/\\____/ \\___//_/|_|  (_)\n",
            "    \n",
            "Version Information: \n",
            "\tBasicSR: 1.3.4.9\n",
            "\tPyTorch: 2.3.0+cu121\n",
            "\tTorchVision: 0.18.0+cu121\n",
            "2024-05-31 04:03:40,719 INFO: \n",
            "  name: HAT_GAN_Real_SRx4\n",
            "  model_type: HATModel\n",
            "  scale: 4\n",
            "  num_gpu: 1\n",
            "  manual_seed: 0\n",
            "  tile:[\n",
            "    tile_size: 512\n",
            "    tile_pad: 32\n",
            "  ]\n",
            "  datasets:[\n",
            "    test_1:[\n",
            "      name: custom\n",
            "      type: SingleImageDataset\n",
            "      dataroot_lq: input_dir\n",
            "      io_backend:[\n",
            "        type: disk\n",
            "      ]\n",
            "      phase: test\n",
            "      scale: 4\n",
            "    ]\n",
            "  ]\n",
            "  network_g:[\n",
            "    type: HAT\n",
            "    upscale: 4\n",
            "    in_chans: 3\n",
            "    img_size: 64\n",
            "    window_size: 16\n",
            "    compress_ratio: 3\n",
            "    squeeze_factor: 30\n",
            "    conv_scale: 0.01\n",
            "    overlap_ratio: 0.5\n",
            "    img_range: 1.0\n",
            "    depths: [6, 6, 6, 6, 6, 6]\n",
            "    embed_dim: 180\n",
            "    num_heads: [6, 6, 6, 6, 6, 6]\n",
            "    mlp_ratio: 2\n",
            "    upsampler: pixelshuffle\n",
            "    resi_connection: 1conv\n",
            "  ]\n",
            "  path:[\n",
            "    pretrain_network_g: ./experiments/pretrained_models/Real_HAT_GAN_SRx4.pth\n",
            "    strict_load_g: True\n",
            "    param_key_g: params_ema\n",
            "    results_root: /content/drive/MyDrive/Colab Notebooks/Intro_to_image_processing/Final_Project/HAT/results/HAT_GAN_Real_SRx4\n",
            "    log: /content/drive/MyDrive/Colab Notebooks/Intro_to_image_processing/Final_Project/HAT/results/HAT_GAN_Real_SRx4\n",
            "    visualization: /content/drive/MyDrive/Colab Notebooks/Intro_to_image_processing/Final_Project/HAT/results/HAT_GAN_Real_SRx4/visualization\n",
            "  ]\n",
            "  val:[\n",
            "    save_img: True\n",
            "    suffix: None\n",
            "  ]\n",
            "  dist: False\n",
            "  rank: 0\n",
            "  world_size: 1\n",
            "  auto_resume: False\n",
            "  is_train: False\n",
            "\n",
            "2024-05-31 04:03:40,722 INFO: Dataset [SingleImageDataset] - custom is built.\n",
            "2024-05-31 04:03:40,722 INFO: Number of test images in custom: 15\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "2024-05-31 04:03:41,279 INFO: Network [HAT] is created.\n",
            "2024-05-31 04:03:41,646 INFO: Network: HAT, with parameters: 20,772,507\n",
            "2024-05-31 04:03:41,646 INFO: HAT(\n",
            "  (conv_first): Conv2d(3, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (patch_embed): PatchEmbed(\n",
            "    (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (patch_unembed): PatchUnEmbed()\n",
            "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
            "  (layers): ModuleList(\n",
            "    (0): RHAG(\n",
            "      (residual_group): AttenBlocks(\n",
            "        (blocks): ModuleList(\n",
            "          (0): HAB(\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): WindowAttention(\n",
            "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "              (softmax): Softmax(dim=-1)\n",
            "            )\n",
            "            (conv_block): CAB(\n",
            "              (cab): Sequential(\n",
            "                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (3): ChannelAttention(\n",
            "                  (attention): Sequential(\n",
            "                    (0): AdaptiveAvgPool2d(output_size=1)\n",
            "                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))\n",
            "                    (2): ReLU(inplace=True)\n",
            "                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))\n",
            "                    (4): Sigmoid()\n",
            "                  )\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "            (drop_path): Identity()\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (act): GELU(approximate='none')\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1-5): 5 x HAB(\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): WindowAttention(\n",
            "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "              (softmax): Softmax(dim=-1)\n",
            "            )\n",
            "            (conv_block): CAB(\n",
            "              (cab): Sequential(\n",
            "                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (3): ChannelAttention(\n",
            "                  (attention): Sequential(\n",
            "                    (0): AdaptiveAvgPool2d(output_size=1)\n",
            "                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))\n",
            "                    (2): ReLU(inplace=True)\n",
            "                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))\n",
            "                    (4): Sigmoid()\n",
            "                  )\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "            (drop_path): DropPath()\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (act): GELU(approximate='none')\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (overlap_attn): OCAB(\n",
            "          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "          (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
            "          (unfold): Unfold(kernel_size=(24, 24), dilation=1, padding=4, stride=16)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (proj): Linear(in_features=180, out_features=180, bias=True)\n",
            "          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (patch_embed): PatchEmbed()\n",
            "      (patch_unembed): PatchUnEmbed()\n",
            "    )\n",
            "    (1-5): 5 x RHAG(\n",
            "      (residual_group): AttenBlocks(\n",
            "        (blocks): ModuleList(\n",
            "          (0-5): 6 x HAB(\n",
            "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): WindowAttention(\n",
            "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "              (softmax): Softmax(dim=-1)\n",
            "            )\n",
            "            (conv_block): CAB(\n",
            "              (cab): Sequential(\n",
            "                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (1): GELU(approximate='none')\n",
            "                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (3): ChannelAttention(\n",
            "                  (attention): Sequential(\n",
            "                    (0): AdaptiveAvgPool2d(output_size=1)\n",
            "                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))\n",
            "                    (2): ReLU(inplace=True)\n",
            "                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))\n",
            "                    (4): Sigmoid()\n",
            "                  )\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "            (drop_path): DropPath()\n",
            "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "              (act): GELU(approximate='none')\n",
            "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "              (drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (overlap_attn): OCAB(\n",
            "          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "          (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
            "          (unfold): Unfold(kernel_size=(24, 24), dilation=1, padding=4, stride=16)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (proj): Linear(in_features=180, out_features=180, bias=True)\n",
            "          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (patch_embed): PatchEmbed()\n",
            "      (patch_unembed): PatchUnEmbed()\n",
            "    )\n",
            "  )\n",
            "  (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
            "  (conv_after_body): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv_before_upsample): Sequential(\n",
            "    (0): Conv2d(180, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "  )\n",
            "  (upsample): Upsample(\n",
            "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): PixelShuffle(upscale_factor=2)\n",
            "    (2): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): PixelShuffle(upscale_factor=2)\n",
            "  )\n",
            "  (conv_last): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            ")\n",
            "2024-05-31 04:03:42,258 INFO: Loading HAT model from ./experiments/pretrained_models/Real_HAT_GAN_SRx4.pth, with param key: [params_ema].\n",
            "2024-05-31 04:03:42,431 INFO: Model [HATModel] is created.\n",
            "2024-05-31 04:03:42,431 INFO: Testing custom...\n",
            "\tTile 1/1\n",
            "\tTile 1/1\n",
            "\tTile 1/1\n",
            "\tTile 1/1\n",
            "\tTile 1/1\n",
            "\tTile 1/1\n",
            "\tTile 1/1\n",
            "\tTile 1/1\n",
            "\tTile 1/1\n",
            "\tTile 1/1\n",
            "\tTile 1/1\n",
            "\tTile 1/1\n",
            "\tTile 1/1\n",
            "\tTile 1/1\n",
            "\tTile 1/1\n"
          ]
        }
      ]
    }
  ]
}